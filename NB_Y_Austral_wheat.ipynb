{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой переменной является столбец **RainTomorrow**. Значение этой переменной мы и будем пытаться предсказать.\n",
    "\n",
    "* Date — дата, в которую зафиксировано наблюдение;\n",
    "* Location — местонахождение метеорологической станции;\n",
    "* MinTemp — минимальная температура (℃);\n",
    "* MaxTemp — максимальная температура (℃);\n",
    "* Rainfall — количество осадков (дождь) за сутки (мм);\n",
    "* Evaporation — количество испарений до 9 утра (мм);\n",
    "* Sunshine — количество часов в сутках, когда светило солнце;\n",
    "* WindGustDir — направление самого сильного порыва ветра за последние 24 часа;\n",
    "* WindGustSpeed — скорость самого сильного порыва ветра за последние 24 часа;\n",
    "* WindDir9am — направление ветра в 9 утра;\n",
    "* WindDir3pm — направление ветра в 3 часа дня;\n",
    "* WindSpeed9am — скорость ветра в 9 часов утра;\n",
    "* WindSpeed3pm — скорость ветра в 3 часа дня;\n",
    "* Humidity9am — влажность в 9 утра;\n",
    "* Humidity3pm — влажность в 3 часа дня;\n",
    "* Pressure9am — атмосферное давление в 9 утра;\n",
    "* Pressure3pm — атмосферное давление в 3 часа дня;\n",
    "* Cloud9am — часть неба, закрытая облаками, в 9 утра;\n",
    "* Cloud3pm — часть неба, закрытая облаками, в 3 часа дня;\n",
    "* Temp9am — температура в 9 утра;\n",
    "* Temp3pm — температура в 3 часа дня;\n",
    "* RainToday — наличие дождя в этот день;\n",
    "* RainTomorrow — наличие дождя на следующий день.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/weatherAUS.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date             0.000000\n",
       "Location         0.000000\n",
       "MinTemp          0.010209\n",
       "MaxTemp          0.008669\n",
       "Rainfall         0.022419\n",
       "Evaporation      0.431665\n",
       "Sunshine         0.480098\n",
       "WindGustDir      0.070989\n",
       "WindGustSpeed    0.070555\n",
       "WindDir9am       0.072639\n",
       "WindDir3pm       0.029066\n",
       "WindSpeed9am     0.012148\n",
       "WindSpeed3pm     0.021050\n",
       "Humidity9am      0.018246\n",
       "Humidity3pm      0.030984\n",
       "Pressure9am      0.103568\n",
       "Pressure3pm      0.103314\n",
       "Cloud9am         0.384216\n",
       "Cloud3pm         0.408071\n",
       "Temp9am          0.012148\n",
       "Temp3pm          0.024811\n",
       "RainToday        0.022419\n",
       "RainTomorrow     0.022460\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.isnull().sum().sum())\n",
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145460, 23)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date             0.000000\n",
      "Location         0.000000\n",
      "MinTemp          0.010209\n",
      "MaxTemp          0.008669\n",
      "Rainfall         0.022419\n",
      "WindGustDir      0.070989\n",
      "WindGustSpeed    0.070555\n",
      "WindDir9am       0.072639\n",
      "WindDir3pm       0.029066\n",
      "WindSpeed9am     0.012148\n",
      "WindSpeed3pm     0.021050\n",
      "Humidity9am      0.018246\n",
      "Humidity3pm      0.030984\n",
      "Pressure9am      0.103568\n",
      "Pressure3pm      0.103314\n",
      "Cloud9am         0.384216\n",
      "Temp9am          0.012148\n",
      "Temp3pm          0.024811\n",
      "RainToday        0.022419\n",
      "RainTomorrow     0.022460\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145460, 20)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаем копию исходной таблицы\n",
    "drop_data = data.copy()\n",
    "# #задаем минимальный порог: вычисляем 60% от числа строк\n",
    "# thresh = drop_data.shape[0]*0.6\n",
    "# #удаляем столбцы, в которых более 40% (100-60) пропусков\n",
    "# drop_data = drop_data.dropna(how='any', thresh=thresh, axis=1)\n",
    "# #удаляем записи, в которых есть хотя бы 1 пропуск\n",
    "# drop_data = drop_data.dropna(how='any', axis=0)\n",
    "# #отображаем результирующую долю пропусков\n",
    "\n",
    "drop_data.drop(['Evaporation','Sunshine','Cloud3pm'], axis = 1, inplace = True)\n",
    "print(drop_data.isnull().mean())\n",
    "drop_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22419285648984874"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_data['RainToday'] = drop_data['RainToday'].apply(lambda x : 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
    "drop_data['RainTomorrow'] = drop_data['RainTomorrow'].apply(lambda x : 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
    "\n",
    "# drop_data.RainToday = drop_data.RainToday.map({'No': 0, 'Yes': 1}, na_action='ignore')\n",
    "# drop_data.RainTomorrow = drop_data.RainTomorrow.map({'No': 0, 'Yes': 1}, na_action='ignore')\n",
    "\n",
    "drop_data['RainToday'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.4\n",
    "\n",
    "Обработайте признак Date таким образом, чтобы выделить в отдельный признак Month (номер месяца). Изначальный признак Date удалите. Определите, в какой месяц в среднем за день выпадает больше всего дождей. В качестве ответа введите порядковый номер месяца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RainToday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2901.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2176.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RainToday\n",
       "Month           \n",
       "6         3267.0\n",
       "7         3189.0\n",
       "8         2978.0\n",
       "5         2901.0\n",
       "3         2831.0\n",
       "9         2600.0\n",
       "4         2451.0\n",
       "1         2447.0\n",
       "11        2415.0\n",
       "10        2321.0\n",
       "12        2304.0\n",
       "2         2176.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_data.Date = pd.to_datetime(drop_data.Date)\n",
    "drop_data['Month'] = drop_data.Date.dt.month\n",
    "drop_data.drop('Date', axis = 1, inplace = True)\n",
    "data_season = drop_data.groupby('Month').sum()\n",
    "data_season[['RainToday']]\n",
    "data_season[['RainToday']].sort_values(by='RainToday', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145460, 124)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dumm = pd.get_dummies(drop_data, columns=['Month', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], drop_first=True)\n",
    "# data_dumm = pd.concat([drop_data, dumm], axis=1)\n",
    "# data_dumm.shape \n",
    "\n",
    "categoricals = ['Month', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "data_dumm = pd.get_dummies(drop_data, columns=categoricals)\n",
    "data_dumm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78257, 124)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dumm.dropna(inplace=True)\n",
    "data_dumm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.6\n",
    "\n",
    "Осталось совсем немного. Удалите все строки, где есть пропуски. Далее разбейте данные на обучающую и тестовую выборки в соотношении 70/30, в качестве значения параметра random_state возьмите число 31.\n",
    "\n",
    "Каково среднее значение целевой переменной на тестовой выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (54779, 123)\n",
      "Test shape: (23478, 123)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22770253002811142"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_dumm.drop('RainTomorrow', axis=1) \n",
    "y = data_dumm['RainTomorrow']\n",
    "\n",
    "# Формируем обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=31)\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.7\n",
    "\n",
    "Теперь давайте вспомним про бутстреп. Он не понадобится нам для решения этой задачи, но будет полезно реализовать его «вручную».\n",
    "\n",
    "Сделайте оценку стандартного отклонения для среднего значения минимальной температуры для обучающей выборки (то есть для среднего значения по признаку MinTemp). Для этого сгенерируйте 1000 случайных выборок из наших данных — каждая из них должна быть такого же объёма, как и обучающая выборка. Для генерации выборки используйте np.random.randint(): сгенерируйте необходимое количество индексов и по ним извлеките соответствующие элементы выборки. Случайность фиксируйте с помощью np.random.seed(31).\n",
    "\n",
    "Для каждой выборки вычислите среднее значение, а после найдите стандартное отклонение для этих значений. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02879072820657669"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(31) #задаём параметр генератора случайных чисел\n",
    "\n",
    "def generat_buts(data, n):     \n",
    "    inx = np.random.randint(0, len(data), (n, len(data))) #определяем индексы случайным образом\n",
    "    numbers = data[inx] #выбираем значения по индексам\n",
    "    return numbers\n",
    "target = X_train['MinTemp'].values #выбираем целевую переменную\n",
    "\n",
    "mean_values = [np.mean(x) for x in generat_buts(target, 1000)] #получаем все средние значения\n",
    "np.std(mean_values) #находим для них стандартное отклонение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4.8\n",
    "\n",
    "Теперь можно перейти к обучению прогностических моделей. Начнём с того, что построим простейшую логистическую регрессию (без настройки гиперпараметров). Это будет та модель, с качеством которой мы будем сравнивать результаты, полученные далее, чтобы оценить превосходство случайного леса над простыми методами.\n",
    "\n",
    "В качестве ответа введите значение метрики roc_auc на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78257 entries, 0 to 145458\n",
      "Columns: 124 entries, MinTemp to WindDir3pm_WSW\n",
      "dtypes: float64(15), uint8(109)\n",
      "memory usage: 17.7 MB\n"
     ]
    }
   ],
   "source": [
    "data_dumm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7266715739397553"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plr = LogisticRegression()\n",
    "plr.fit(X_train, y_train)\n",
    "pred_train = plr.predict(X_train)\n",
    "pred_test = plr.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.9\n",
    "\n",
    "Теперь попробуйте обучить на наших данных другой алгоритм — дерево решений. С помощью GridSearchCV сделайте перебор гиперпараметров по следующей сетке:\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 10)), 'min_samples_split': [2, 3, 4], 'max_depth': [5,7,9,11]}\n",
    "\n",
    "Для параметра кросс-валидации cv задайте значение 3. Для решающего дерева определите параметр random_state=42. Остальные параметры оставьте по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_leaf_nodes': 9, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_9 = {'max_leaf_nodes': list(range(2, 10)), 'min_samples_split': [2, 3, 4], 'max_depth': [5,7,9,11]}\n",
    "# grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=3, cv=3)\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params_9, cv=3)\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033229072349596"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 5, max_leaf_nodes = 9, min_samples_split = 2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_train_9 = clf.predict(X_train)\n",
    "pred_test_9 = clf.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329684570290497"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf =  RandomForestClassifier(n_estimators = 100, random_state=31)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "pred_train_10 = clf_rf.predict(X_train)\n",
    "pred_test_10 = clf_rf.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=3; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=3; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=3; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=5; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=5; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=7; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=7; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=7; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=9; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=9; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=4, min_samples_leaf=9; total time=   1.0s\n",
      "[CV] END ...max_depth=5, max_features=4, min_samples_leaf=11; total time=   1.0s\n",
      "[CV] END ...max_depth=5, max_features=4, min_samples_leaf=11; total time=   1.0s\n",
      "[CV] END ...max_depth=5, max_features=4, min_samples_leaf=11; total time=   1.0s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=3; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=5; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=7; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=9; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=9; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=5, min_samples_leaf=9; total time=   1.1s\n",
      "[CV] END ...max_depth=5, max_features=5, min_samples_leaf=11; total time=   1.1s\n",
      "[CV] END ...max_depth=5, max_features=5, min_samples_leaf=11; total time=   1.1s\n",
      "[CV] END ...max_depth=5, max_features=5, min_samples_leaf=11; total time=   1.1s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=3; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=5; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=7; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=9; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=9; total time=   1.2s\n",
      "[CV] END ....max_depth=5, max_features=6, min_samples_leaf=9; total time=   1.2s\n",
      "[CV] END ...max_depth=5, max_features=6, min_samples_leaf=11; total time=   1.2s\n",
      "[CV] END ...max_depth=5, max_features=6, min_samples_leaf=11; total time=   1.2s\n",
      "[CV] END ...max_depth=5, max_features=6, min_samples_leaf=11; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=3; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=3; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=3; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=5; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=5; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=5; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=7; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=7; total time=   1.4s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=7; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=9; total time=   1.4s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=9; total time=   1.3s\n",
      "[CV] END ....max_depth=5, max_features=7, min_samples_leaf=9; total time=   1.4s\n",
      "[CV] END ...max_depth=5, max_features=7, min_samples_leaf=11; total time=   1.3s\n",
      "[CV] END ...max_depth=5, max_features=7, min_samples_leaf=11; total time=   1.4s\n",
      "[CV] END ...max_depth=5, max_features=7, min_samples_leaf=11; total time=   1.4s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=3; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=3; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=5; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=5; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=5; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=7; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=7; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=7; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=9; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=9; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=4, min_samples_leaf=9; total time=   1.6s\n",
      "[CV] END ..max_depth=10, max_features=4, min_samples_leaf=11; total time=   1.6s\n",
      "[CV] END ..max_depth=10, max_features=4, min_samples_leaf=11; total time=   1.6s\n",
      "[CV] END ..max_depth=10, max_features=4, min_samples_leaf=11; total time=   1.6s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=3; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=5; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=5; total time=   1.9s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=7; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=7; total time=   1.9s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=9; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=9; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=5, min_samples_leaf=9; total time=   1.8s\n",
      "[CV] END ..max_depth=10, max_features=5, min_samples_leaf=11; total time=   1.8s\n",
      "[CV] END ..max_depth=10, max_features=5, min_samples_leaf=11; total time=   1.8s\n",
      "[CV] END ..max_depth=10, max_features=5, min_samples_leaf=11; total time=   1.8s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=3; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=3; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=3; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=5; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=5; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=5; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=7; total time=   2.1s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=9; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=9; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=6, min_samples_leaf=9; total time=   2.0s\n",
      "[CV] END ..max_depth=10, max_features=6, min_samples_leaf=11; total time=   2.0s\n",
      "[CV] END ..max_depth=10, max_features=6, min_samples_leaf=11; total time=   2.0s\n",
      "[CV] END ..max_depth=10, max_features=6, min_samples_leaf=11; total time=   2.0s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=5; total time=   2.3s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=5; total time=   2.3s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=7; total time=   2.3s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=9; total time=   2.2s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=9; total time=   2.3s\n",
      "[CV] END ...max_depth=10, max_features=7, min_samples_leaf=9; total time=   2.3s\n",
      "[CV] END ..max_depth=10, max_features=7, min_samples_leaf=11; total time=   2.3s\n",
      "[CV] END ..max_depth=10, max_features=7, min_samples_leaf=11; total time=   2.3s\n",
      "[CV] END ..max_depth=10, max_features=7, min_samples_leaf=11; total time=   2.3s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=3; total time=   2.3s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=3; total time=   2.2s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=5; total time=   2.2s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=5; total time=   2.1s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=5; total time=   2.3s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=7; total time=   2.3s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=7; total time=   2.2s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=9; total time=   2.1s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=9; total time=   2.2s\n",
      "[CV] END ...max_depth=15, max_features=4, min_samples_leaf=9; total time=   2.1s\n",
      "[CV] END ..max_depth=15, max_features=4, min_samples_leaf=11; total time=   2.2s\n",
      "[CV] END ..max_depth=15, max_features=4, min_samples_leaf=11; total time=   2.2s\n",
      "[CV] END ..max_depth=15, max_features=4, min_samples_leaf=11; total time=   2.1s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=3; total time=   2.6s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=5; total time=   2.5s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=5; total time=   2.4s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=7; total time=   2.4s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=7; total time=   2.5s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=7; total time=   2.4s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=9; total time=   2.4s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=9; total time=   2.4s\n",
      "[CV] END ...max_depth=15, max_features=5, min_samples_leaf=9; total time=   2.4s\n",
      "[CV] END ..max_depth=15, max_features=5, min_samples_leaf=11; total time=   2.3s\n",
      "[CV] END ..max_depth=15, max_features=5, min_samples_leaf=11; total time=   2.3s\n",
      "[CV] END ..max_depth=15, max_features=5, min_samples_leaf=11; total time=   2.3s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=3; total time=   2.9s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=3; total time=   2.9s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=3; total time=   3.0s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=5; total time=   2.8s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=5; total time=   2.8s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=5; total time=   2.9s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=7; total time=   3.0s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=7; total time=   2.9s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=7; total time=   2.9s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=9; total time=   2.9s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=9; total time=   2.8s\n",
      "[CV] END ...max_depth=15, max_features=6, min_samples_leaf=9; total time=   2.8s\n",
      "[CV] END ..max_depth=15, max_features=6, min_samples_leaf=11; total time=   2.7s\n",
      "[CV] END ..max_depth=15, max_features=6, min_samples_leaf=11; total time=   2.7s\n",
      "[CV] END ..max_depth=15, max_features=6, min_samples_leaf=11; total time=   2.8s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=3; total time=   3.6s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=3; total time=   3.5s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=3; total time=   3.4s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=5; total time=   3.2s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=5; total time=   3.1s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=5; total time=   3.2s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=7; total time=   3.1s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=7; total time=   3.1s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=7; total time=   3.2s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=9; total time=   3.2s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=9; total time=   3.1s\n",
      "[CV] END ...max_depth=15, max_features=7, min_samples_leaf=9; total time=   3.2s\n",
      "[CV] END ..max_depth=15, max_features=7, min_samples_leaf=11; total time=   2.9s\n",
      "[CV] END ..max_depth=15, max_features=7, min_samples_leaf=11; total time=   3.0s\n",
      "[CV] END ..max_depth=15, max_features=7, min_samples_leaf=11; total time=   3.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'max_features': 7, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_11 = {'max_features': [4, 5, 6, 7], 'min_samples_leaf': [3, 5, 7, 9, 11], 'max_depth': [5, 10, 15]}\n",
    "grid_search_cv_11 = GridSearchCV(RandomForestClassifier(random_state=31), params_11, verbose=2, cv=3)\n",
    "grid_search_cv_11.fit(X_train, y_train)\n",
    "grid_search_cv_11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005484843285417"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf_bes =  RandomForestClassifier(n_estimators = 100, max_depth = 15, max_features = 7, min_samples_leaf = 3, random_state=31)\n",
    "clf_rf_bes.fit(X_train, y_train)\n",
    "pred_train_11 = clf_rf_bes.predict(X_train)\n",
    "pred_test_11 = clf_rf_bes.predict(X_test)\n",
    "roc_auc_score(y_test, pred_test_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Humidity3pm</td>\n",
       "      <td>0.250783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainfall</td>\n",
       "      <td>0.079757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Humidity9am</td>\n",
       "      <td>0.070403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cloud9am</td>\n",
       "      <td>0.067092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pressure3pm</td>\n",
       "      <td>0.065272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Location_Newcastle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Location_SalmonGums</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Location_Nhil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Location_NorahHead</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Location_GoldCoast</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feat      coef\n",
       "7           Humidity3pm  0.250783\n",
       "2              Rainfall  0.079757\n",
       "6           Humidity9am  0.070403\n",
       "10             Cloud9am  0.067092\n",
       "9           Pressure3pm  0.065272\n",
       "..                  ...       ...\n",
       "50   Location_Newcastle  0.000000\n",
       "62  Location_SalmonGums  0.000000\n",
       "51        Location_Nhil  0.000000\n",
       "52   Location_NorahHead  0.000000\n",
       "40   Location_GoldCoast  0.000000\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [x for x in data_dumm if x != 'RainTomorrow']\n",
    "pd.DataFrame({'feat': feature_names,\n",
    "              'coef': clf_rf_bes.feature_importances_}).sort_values(by='coef', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
